{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNLvIT583YnC19bwpe3rJCo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/harshyadav1508/GenAiPoc/blob/main/langchainv0.1.0/langchainRAGIntro.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "j0Lt08b5R7q9"
      },
      "outputs": [],
      "source": [
        "! pip install langchain\n",
        "! pip install langchain-openai\n",
        "! pip install beautifulsoup4\n",
        "! pip install faiss-cpu"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import openai\n",
        "from langchain_openai import AzureChatOpenAI, ChatOpenAI"
      ],
      "metadata": {
        "id": "WU1nlChFSImb"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ[\"AZURE_OPENAI_API_KEY\"] = \"***\"\n",
        "os.environ[\"AZURE_OPENAI_ENDPOINT\"] = 'https://caip-azure-openai.openai.azure.com/'\n",
        "os.environ[\"OPENAI_API_VERSION\"]    = \"2023-07-01-preview\""
      ],
      "metadata": {
        "id": "g6coGd4wSKre"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm = AzureChatOpenAI(\n",
        "    azure_deployment=\"gpt-4\",\n",
        "    openai_api_type=\"azure\"\n",
        ")\n"
      ],
      "metadata": {
        "id": "_W2dxdgHSNm_"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.document_loaders import WebBaseLoader\n",
        "\n",
        "loader = WebBaseLoader(\"https://blog.langchain.dev/langchain-v0-1-0/\")\n",
        "\n",
        "docs = loader.load()"
      ],
      "metadata": {
        "id": "i5-5SSMqiwKL"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.vectorstores import FAISS\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter()\n",
        "documents = text_splitter.split_documents(docs)"
      ],
      "metadata": {
        "id": "ztHQLIftiyTk"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import AzureOpenAIEmbeddings\n",
        "\n",
        "os.environ[\"AZURE_OPENAI_API_KEY\"] = \"***\"\n",
        "os.environ[\"AZURE_OPENAI_ENDPOINT\"] = \"https://caip-openai-dev.openai.azure.com/\"\n",
        "\n",
        "embeddings = AzureOpenAIEmbeddings(\n",
        "\n",
        "    # azure_deployment=\"text-davinci-002\",\n",
        "    openai_api_type=\"azure\",\n",
        "    openai_api_version=\"2023-07-01-preview\",\n",
        "    )\n",
        "vectorstore = FAISS.from_documents(documents,embeddings)"
      ],
      "metadata": {
        "id": "TdT_4hDeL7fB"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create chain for docs\n",
        "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "\n",
        "\n",
        "template=\"\"\"\n",
        "Answer the following question based only on the provided context:\n",
        "<context>{context}</context>\n",
        "\n",
        "Question:{input}\n",
        "\"\"\"\n",
        "prompt = ChatPromptTemplate.from_template(template)\n",
        "document_chain =create_stuff_documents_chain(llm,prompt)"
      ],
      "metadata": {
        "id": "006-9BYUjEDS"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create retrieval chain\n",
        "\n",
        "from langchain.chains import create_retrieval_chain\n",
        "\n",
        "retriever = vectorstore.as_retriever()\n",
        "retrieval_chain = create_retrieval_chain(retriever, document_chain)"
      ],
      "metadata": {
        "id": "d-pWs_KzjIHz"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = retrieval_chain.invoke({\n",
        "    \"input\": \"what is new in langchain 0.1.0\"\n",
        "})\n",
        "response[\"answer\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "l3RbrFZmkB5r",
        "outputId": "2a685682-da48-44d3-a542-a7082eb16569"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'LangChain 0.1.0 is the first stable version that is fully backwards compatible and comes in both Python and JavaScript. It features improved focus through both functionality and documentation and introduces a new versioning standard. This release aims to earn developer trust and allows for the systematic and safe evolution of the library.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# conversational retrieval chain\n",
        "\n",
        "from langchain.chains import create_history_aware_retriever\n",
        "from langchain_core.prompts import MessagesPlaceholder\n",
        "\n",
        "prompt = ChatPromptTemplate.from_messages([\n",
        "    MessagesPlaceholder(variable_name=\"chat_history\"),\n",
        "    (\"user\", \"{input}\"),\n",
        "    (\"user\", \"Given the above conversation, generate a search query to look up in order to get information relevant to the conversation\")\n",
        "])\n",
        "\n",
        "retriever_chain = create_history_aware_retriever(llm, retriever, prompt)"
      ],
      "metadata": {
        "id": "3fHQrJvRkI5Y"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.messages import HumanMessage, AIMessage\n",
        "\n",
        "chat_history = [\n",
        "    HumanMessage(content=\"Is there anything new about Langchain 0.1.0?\"),\n",
        "    AIMessage(content=\"Yes!\")\n",
        "]\n",
        "\n",
        "retriever_chain.invoke({\n",
        "    \"chat_history\": chat_history,\n",
        "    \"input\": \"Tell me more about it!\"\n",
        "})"
      ],
      "metadata": {
        "id": "V3j3sgM2kOKQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import create_retrieval_chain\n",
        "\n",
        "prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", \"Answer the user's questions based on the below context:\\n\\n{context}\"),\n",
        "    MessagesPlaceholder(variable_name=\"chat_history\"),\n",
        "    (\"user\", \"{input}\")\n",
        "])\n",
        "\n",
        "document_chain = create_stuff_documents_chain(llm, prompt)\n",
        "\n",
        "conversational_retrieval_chain = create_retrieval_chain(retriever_chain, document_chain)"
      ],
      "metadata": {
        "id": "X56DVZpVkUEZ"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# simulate conversation history\n",
        "\n",
        "chat_history = [\n",
        "    HumanMessage(content=\"Is there anything new about Langchain 0.1.0?\"),\n",
        "    AIMessage(content=\"Yes!\")\n",
        "]\n",
        "\n",
        "response = conversational_retrieval_chain.invoke({\n",
        "    'chat_history': chat_history,\n",
        "    \"input\": \"Tell me more about it!\"\n",
        "})"
      ],
      "metadata": {
        "id": "ID_ii60Akdku"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response['answer']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "id": "-v7BJEChkmSD",
        "outputId": "60f48339-8566-4ca0-a108-d48e9b9b80d0"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'LangChain 0.1.0 is the first stable version and brings several improvements and changes:\\n\\n1. Fully backwards compatible: This version maintains compatibility with previous versions, making it easier for developers to upgrade without worrying about breaking changes.\\n2. Available in both Python and JavaScript: LangChain 0.1.0 has been developed for both Python and JavaScript, ensuring a broader reach for developers.\\n3. Improved focus through functionality and documentation: The new version comes with enhanced features and better documentation, making it more user-friendly.\\n4. New versioning standard: From 0.1.0 onwards, breaking changes to the public API will result in a minor version bump, and bug fixes or new features will result in a patch version bump. This will help developers update with confidence and allow the LangChain team to deprecate and delete old code more responsibly.\\n\\nOther notable changes include architectural updates, separating langchain-core and partner packages, and improvements in third-party integrations, observability, and composability. The release of langchain 0.1.0 aims to provide a more stable, robust, and developer-friendly experience.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DRUxD3bAkpL0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}